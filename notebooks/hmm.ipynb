{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import Bounds, LinearConstraint, minimize\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionModel(ABC):\n",
    "    _NUM_ACTIONS = 2\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: np.ndarray,\n",
    "        param_names: list[str],\n",
    "        param_bounds: Bounds | None = None,\n",
    "        param_constraints: LinearConstraint | None = None,\n",
    "    ) -> None:\n",
    "        if type(params) is not np.ndarray:\n",
    "            raise ValueError(\"'params' must be a numpy array.\")\n",
    "        if len(params) != len(param_names):\n",
    "            raise ValueError(\"Length of 'params' must match length of 'param_names'.\")\n",
    "        self._params = params\n",
    "        self._param_names = param_names\n",
    "        self._param_bounds = param_bounds\n",
    "        self._param_constraints = param_constraints\n",
    "\n",
    "    @property\n",
    "    def params(self) -> np.ndarray:\n",
    "        return self._params\n",
    "\n",
    "    @params.setter\n",
    "    def params(self, new_params: np.ndarray) -> None:\n",
    "        self._params = new_params\n",
    "\n",
    "    @property\n",
    "    def param_bounds(self) -> Bounds | None:\n",
    "        return self._param_bounds\n",
    "\n",
    "    @property\n",
    "    def param_constraints(self) -> LinearConstraint | None:\n",
    "        return self._param_constraints\n",
    "\n",
    "    @abstractmethod\n",
    "    def action_probabilities(self, stimuli: float | np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def sample(self, stimuli: float | np.ndarray) -> np.ndarray:\n",
    "        probabilities = self.action_probabilities(stimuli)\n",
    "        if probabilities.ndim == 1:\n",
    "            probabilities = probabilities.reshape(1, -1)\n",
    "        return np.array(\n",
    "            [np.random.choice(self._NUM_ACTIONS, p=prob) for prob in probabilities]\n",
    "        )\n",
    "\n",
    "    def likelihood(\n",
    "        self, stimuli: float | np.ndarray, actions: float | np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        probabilities = self.action_probabilities(stimuli)\n",
    "        if type(actions) is not np.ndarray:\n",
    "            return probabilities[0, actions]\n",
    "        likelihoods = np.zeros_like(actions, dtype=float)\n",
    "        for i in range(probabilities.shape[-1]):\n",
    "            likelihoods[actions == i] = probabilities[actions == i, i]\n",
    "        return likelihoods\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        param_str = \", \".join(\n",
    "            f\"{name}={value}\" for name, value in zip(self._param_names, self.params)\n",
    "        )\n",
    "        return f\"{self.__class__.__name__}({param_str})\"\n",
    "\n",
    "\n",
    "class CategoricalDecisionModel(DecisionModel):\n",
    "    def __init__(self, probabilities: np.ndarray | list | None = None) -> None:\n",
    "        if probabilities is None:\n",
    "            probabilities = np.random.random(self._NUM_ACTIONS)\n",
    "            probabilities /= probabilities.sum()\n",
    "        elif type(probabilities) is list:\n",
    "            probabilities = np.array(probabilities)\n",
    "        param_names = [f\"p{i}\" for i in range(len(probabilities))]\n",
    "        param_bounds = Bounds(0, 1, keep_feasible=True)\n",
    "        param_constraints = LinearConstraint(np.ones(self._NUM_ACTIONS), 1, 1)\n",
    "        super().__init__(probabilities, param_names, param_bounds, param_constraints)\n",
    "\n",
    "    def action_probabilities(self, stimuli: float | np.ndarray) -> np.ndarray:\n",
    "        if type(stimuli) is not np.ndarray:\n",
    "            return self._params\n",
    "        return np.tile(self._params, reps=stimuli.shape + (1,))\n",
    "\n",
    "\n",
    "class LogisticDecisionModel(DecisionModel):\n",
    "    def __init__(\n",
    "        self, bias: float | None = None, stim_weight: float | None = None\n",
    "    ) -> None:\n",
    "        if bias is None:\n",
    "            bias = np.random.random()\n",
    "        if stim_weight is None:\n",
    "            stim_weight = np.random.random()\n",
    "        params = np.array([bias, stim_weight])\n",
    "        param_names = [\"bias\", \"w_stim\"]\n",
    "        super().__init__(params, param_names)\n",
    "\n",
    "    def action_probabilities(\n",
    "        self, stimuli: float | np.ndarray | None = None\n",
    "    ) -> np.ndarray:\n",
    "        if type(stimuli) is not np.ndarray:\n",
    "            stimuli = np.array([stimuli])\n",
    "        bias, weight = self._params\n",
    "        p = 1 / (1 + np.exp(-bias - weight * stimuli))\n",
    "        return np.stack([1 - p, p], axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_probs = [0.5, 0.5]\n",
    "transition_probs = np.array(\n",
    "    [\n",
    "        [0.95, 0.05],\n",
    "        [0.02, 0.98],\n",
    "    ]\n",
    ")\n",
    "decision_models = [\n",
    "    LogisticDecisionModel(bias=0.0, stim_weight=5.0),\n",
    "    LogisticDecisionModel(bias=5, stim_weight=0.5),\n",
    "]\n",
    "time_steps = 250\n",
    "num_sequences = 100\n",
    "\n",
    "\n",
    "def generate_data(\n",
    "    initial_probs, transition_probs, decision_models, time_steps, num_sequences\n",
    "):\n",
    "    stimuli = []\n",
    "    data = []\n",
    "    for _ in tqdm(range(num_sequences)):\n",
    "        stim, observations = generate_sequence(\n",
    "            initial_probs, transition_probs, decision_models, time_steps\n",
    "        )\n",
    "        stimuli.append(stim)\n",
    "        data.append(observations)\n",
    "    return np.array(stimuli), np.array(data)\n",
    "\n",
    "\n",
    "def generate_sequence(initial_probs, transition_probs, decision_models, time_steps):\n",
    "    stimuli = np.random.random(time_steps) * 2 - 1\n",
    "    num_states = len(initial_probs)\n",
    "    states = [np.random.choice(num_states, p=initial_probs)]\n",
    "    for _ in range(time_steps - 1):\n",
    "        states.append(np.random.choice(num_states, p=transition_probs[states[-1]]))\n",
    "    observations = []\n",
    "    for stimulus, state in zip(stimuli, states):\n",
    "        observations.append(decision_models[state].sample(stimulus))\n",
    "    observations = np.concatenate(observations)\n",
    "    return stimuli, observations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli, data = generate_data(\n",
    "    initial_probs, transition_probs, decision_models, time_steps, num_sequences\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(\n",
    "    stimuli: np.ndarray,\n",
    "    sequence: np.ndarray,\n",
    "    initial_probs: np.ndarray,\n",
    "    transition_probs: np.ndarray,\n",
    "    decision_models: list[DecisionModel],\n",
    ") -> np.ndarray:\n",
    "    num_states = len(initial_probs)\n",
    "    alpha = np.zeros((num_states, len(sequence)))\n",
    "    alpha[:, 0] = initial_probs * [\n",
    "        dm.likelihood(stimuli[0], sequence[0]) for dm in decision_models\n",
    "    ]\n",
    "    for t in range(1, len(sequence)):\n",
    "        for s in range(num_states):\n",
    "            alpha[s, t] = np.sum(\n",
    "                alpha[:, t - 1] * transition_probs[:, s]\n",
    "            ) * decision_models[s].likelihood(stimuli[t], sequence[t])\n",
    "        alpha[:, t] /= np.sum(alpha[:, t])\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def backward(stimuli, sequence, initial_probs, transition_probs, decision_models):\n",
    "    num_states = len(initial_probs)\n",
    "    beta = np.zeros((num_states, len(sequence)))\n",
    "    beta[:, -1] = 1\n",
    "    for t in range(len(sequence) - 2, -1, -1):\n",
    "        for s in range(num_states):\n",
    "            beta[s, t] = np.sum(\n",
    "                beta[:, t + 1]\n",
    "                * transition_probs[s, :]\n",
    "                * [\n",
    "                    dm.likelihood(stimuli[t + 1], sequence[t + 1])\n",
    "                    for dm in decision_models\n",
    "                ]\n",
    "            )\n",
    "    return beta\n",
    "\n",
    "\n",
    "def e_step(stimuli, data, initial_probs, transition_probs, decision_models):\n",
    "    gamma = []\n",
    "    xi = []\n",
    "    for stim, seq in zip(stimuli, data):\n",
    "        gamma_s, xi_s = e_step_helper(\n",
    "            stim, seq, initial_probs, transition_probs, decision_models\n",
    "        )\n",
    "        gamma.append(gamma_s)\n",
    "        xi.append(xi_s)\n",
    "    gamma = np.array(gamma)\n",
    "    xi = np.array(xi)\n",
    "    return gamma, xi\n",
    "\n",
    "\n",
    "def e_step_helper(stimuli, sequence, initial_probs, transition_probs, decision_models):\n",
    "    num_states = len(initial_probs)\n",
    "    alpha = forward(stimuli, sequence, initial_probs, transition_probs, decision_models)\n",
    "    beta = backward(stimuli, sequence, initial_probs, transition_probs, decision_models)\n",
    "    gamma = alpha * beta\n",
    "    gamma /= np.sum(gamma, axis=0)\n",
    "    xi = np.zeros((num_states, num_states, len(sequence) - 1))\n",
    "    for t in range(len(sequence) - 1):\n",
    "        for i in range(num_states):\n",
    "            for j in range(num_states):\n",
    "                xi[i, j, t] = (\n",
    "                    alpha[i, t]\n",
    "                    * transition_probs[i, j]\n",
    "                    * decision_models[j].likelihood(stimuli[t + 1], sequence[t + 1])\n",
    "                    * beta[j, t + 1]\n",
    "                )\n",
    "    xi /= np.sum(xi, axis=(0, 1))\n",
    "    return gamma, xi\n",
    "\n",
    "\n",
    "def m_step_latents(data, gamma, xi):\n",
    "    initial_probs = np.mean(gamma[:, :, 0], axis=0)\n",
    "    transition_probs = (\n",
    "        np.sum(xi, axis=(0, 3)) / np.sum(gamma[:, :, :-1], axis=(0, 2))[:, np.newaxis]\n",
    "    )\n",
    "    return initial_probs, transition_probs\n",
    "\n",
    "\n",
    "def m_step_observations(stimuli, data, gamma, decision_models):\n",
    "    def decision_model_nll(params, gamma, decision_model):\n",
    "        decision_model.params = params\n",
    "        return -np.sum(gamma * np.log(decision_model.likelihood(stimuli, data)))\n",
    "\n",
    "    for i, dm in enumerate(decision_models):\n",
    "        dm.params = minimize(\n",
    "            decision_model_nll,\n",
    "            dm.params,\n",
    "            args=(gamma[:, i, :], dm),\n",
    "            method=\"trust-constr\",\n",
    "            bounds=dm.param_bounds,\n",
    "            constraints=dm.param_constraints,\n",
    "        ).x\n",
    "\n",
    "\n",
    "def baum_welch(stimuli, data, num_states, model_type, num_iters=100):\n",
    "    initial_probs = np.random.random(num_states)\n",
    "    initial_probs /= initial_probs.sum()\n",
    "    transition_probs = np.random.random((num_states, num_states))\n",
    "    transition_probs /= transition_probs.sum(axis=1)[:, np.newaxis]\n",
    "    decision_models = [model_type() for _ in range(num_states)]\n",
    "    for _ in tqdm(range(num_iters)):\n",
    "        gamma, xi = e_step(\n",
    "            stimuli, data, initial_probs, transition_probs, decision_models\n",
    "        )\n",
    "        initial_probs, transition_probs = m_step_latents(data, gamma, xi)\n",
    "        m_step_observations(stimuli, data, gamma, decision_models)\n",
    "        print(initial_probs)\n",
    "        print(transition_probs)\n",
    "        print([dm.params for dm in decision_models])\n",
    "    return initial_probs, transition_probs, decision_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baum_welch(stimuli, data, 2, LogisticDecisionModel)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
